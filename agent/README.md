到底什么是Agent
============

# 引言
AI Agents 是一个随着大模型热潮而兴起的重要概念。虽然Agent这个词现在被频繁地提起，但它究竟是什么，是如何运作的，很多人其实并不清楚。

什么是Agent
很多人都知道，现在的大模型，比如GPT-4o、DeepSeek之类的，他们回答问题很厉害，逻辑也很强。但平时用他们的时候呢，会发现一个限制：他们无法感知或者是改变外界环境。

这句话是什么意思呢？我举一个例子来给你说明一下。比如，你想让GPT-4o帮你写一个贪吃蛇游戏，它确实可以给你代码，但是写完之后，像把代码写入到文件这种事情，还是得你自己动手。也就是说，大模型无法改变外界环境。

而且有没有一种可能，你其实已经有一些贪吃蛇的代码了，你只是想让模型帮你，基于这些代码来改写，增加一些功能。在这种情况下，你就必须把你已有的代码，复制给GPT-4o才行。不主动告诉GPT-4o的话，他是无法自己查到这些代码的，这就是大模型无法感知外界环境的体现。

所以综合来看，大模型是无法感知或者是改变外部环境的。那有没有办法解决掉这个问题呢？其实是有的，给它接上对应的工具就可以了。比如说是读写文件内容的工具、查看文件列表的工具、运行终端命令的工具。工具就像是大模型的感官和四肢，有了工具，大模型就可以自己查询已有文件，自己写入代码，自己运行程序，整个过程不需要插手，完全自动化。

像这样，把一个大模型和一堆工具组装起来，变成一个能感知和改变外界环境的智能程序，就称它为Agent。通常Agent用一个机器人来表示，这与大模型的大脑图标形成了鲜明的对比，毕竟Agent有了感官和四肢嘛，能自己独立做事了，就像一个机器人一样。

![](./img/img1.png)

# Agent类型
Agent呢有很多类型，前面举的是编程类的Agent，它可以用来开发程序。除此之外，还有一些Agent可以做PPT，有一些Agent可以深度搜索等。总的来说，Agent的类型有很多，擅长的领域呢，也各不相同。

下面来举几个具体点的例子。第一个例子便是大名鼎鼎的claude code。claude code是一个用于编程的Agent，只需要给他提交任务，他便会调用大模型和各种工具，来帮写代码，直至完成任务。整个过程中，你只需要告诉claude code需要做的任务，别的基本上什么也不用动。

再举一个例子，今年年初比较火的Manus，它也是一个Agent。在这个例子中，用户希望Manus帮他比较几个手机的性能、照相等能力，为了解决用户的问题，Manus会生成执行计划，搜索并浏览相关网页，最后把报告整理成一个页面，展示给用户看。整个过程基本上也不需要用户插手，Manus利用大模型和一些工具，就可以解决掉用户的问题。


# ReAct模式

Agent的运行有很多种模式，其中最有名的一种是ReAct。ReAct本身是一个缩写，它的全称是Reasoning And Acting，也就是思考与行动。ReAct可能是目前使用最为广泛的Agent运行模式，如果要学习Agent的实现原理，那你就绝对绕不开ReAct。这个模式最初由2022年10月份的一篇论文提出。虽然距离现在已经有三年的时间了，但是他所提出的Agent的运行模式，仍然有着非常广泛的使用，说他是目前使用最为广泛的Agent的运行模式也不为过。

在这种模式下，用户先提交任务，然后Agent先做思考（英文是Thought）。他思考后会决定是否调用工具，如果是的话，他便会去调用合适的工具，比如读取文件、写入文件内容之类的，ReAct称这一步是行动（英文是Action）。在行动后，Agent会去查看工具的执行结果，比如所读取的文件内容、写入是否成功等等，ReAct称这一步是观察，也就是观察工具执行结果（英文是Observation）。

在观察之后，ReAct会继续思考，它会再次判断是否需要调用工具。如果还是需要的话，他就会继续重复之前所说的行动、观察、思考的流程，直到某个时刻，他认为不需要再调用工具了，可以直接给出结论了，此时他就输出了最终答案（英文是Final Answer），整个流程到此结束。

所以从这个流程里面也可以看出，ReAct流程的核心步骤是Thought、Action、Observation和Final Answer。记住这几个词，后面呢会用到。

了解了ReAct模式的流程之后，下一个问题就是：这种ReAct模式是如何实现的？为什么模型拿到用户问题之后会先思考再行动？他为什么不直接行动？是因为模型就这么训练的吗？不是的，这跟模型的训练过程关系不大，大部分的奥秘呢，其实都集中在系统提示词上。

系统提示词是跟用户问题一起送给模型的提示词，它规定了模型的角色、运行时要遵守的规则以及各种环境的信息等等。比如在系统提示词里面写：你的回答必须包含两个XML标签，一个叫做Question，用于存放用户的问题，一个叫做Answer，用于存放你的回答。你把这个系统提示词和用户问题一起发给大模型，在这种情况下，大模型便会遵循这种规范来输出答案。

上面举的是一个简单的例子，如果你想要模型按照ReAct模式返回答案的话呢，那你的系统提示词就会更加复杂一些。

除了ReAct之外，还有很多其他的运行模式。其中很多Agent的运行过程就是先规划，这种先规划再执行的模式，目前并没有一个统一的名字，而且每个Agent的实现多多少少也会有一些差别。

# Plan And Execute

比较有名的实现是LangChain提出来的Plan And Execute模式。从总体上来看，他也是遵循了先规划再执行的流程，只不过他的流程引入了一些动态修改规划的环节，这使得他的方案有了很大的灵活性。

首先，它里面有一个负责出执行计划的模型，称它为Plan模型。

在运行的过程中还需要根据每一步的执行结果来动态的调整计划，因此还需要一个负责修改执行计划的模型，称它为Replan模型。Plan和Replan模型可以是同一个，也可以分成两个，都是可以的，暂且将它们列为两个。

除了这两个模型之外，还需要一个负责执行这个计划中每一个步骤的Agent，称它为执行Agent。这个Plan And Execute Agent内部呢还有一个Agent，这种Agent套Agent的设计方案其实也是比较常见的。最后跟ReAct那个流程一样，还需要一个Agent的主程序，负责串联整个流程。这就是Plan And Execute Agent的全部模块了。

Plan And Execute各个模块之间是如何运作的。

首先用户会把问题提给Agent的主程序，比如问题是：“今年澳网男子冠军的家乡是哪里？”这里的“澳网”指的是每年举办的澳大利亚网球公开赛，也就是个体育赛事了。Agent主程序接到这个问题之后，会把这个问题发给Plan模型，让它给出具体的执行步骤。

比如一个可能的执行步骤就是这样的：先查询当前日期，然后查询在当前年份下澳网男子冠军的名字（比如当前时间是2025年的话，就查询2025年的澳网男子冠军的名字；如果当前年份是2024年的话，那就查询2024年的澳网男子冠军的名字），查出名字后，再根据这个名字来查询这个冠军的家乡。没错，这就是一个非常合理的执行步骤。

那计划有了之后，Agent的主程序便会把这个计划传给执行Agent，让他去执行这个计划中的第一步，也就是查询当前日期的那个步骤。这个执行Agent可以用之前讲的ReAct模式来运行，它内置一个网络搜索工具，这样呢它就可以通过搜索网络来查询当前日期了。当然，执行Agent也完全可以用别的模式来运行，Plan And Execute模式呢只要求执行Agent能够完成指定的步骤就行，至于它的运行模式是不是ReAct、内置工具有哪些，他完全不关心。

执行Agent内部一顿操作之后，就吐出了一个执行结果，并返回了回去。然后Agent的主程序会把用户问题、执行计划和执行记录都发给Replan模型，让它生成一个新的执行计划。毕竟，拿到了第一步的执行结果了，多了一些信息，情况呢可能发生些变化，把原计划改改是再正常不过的事情了。

那Agent的主程序接到新的执行计划之后，它便会回头再重复这个框中的流程。在这个例子中，这个框中的流程一共会运行三轮，对应了执行计划里面的三步。每一轮都包含两个环节：一个是执行环节，一个是Replan环节。

首先是第一轮。在执行阶段，把执行计划发给执行Agent，让他处理其中的第一步。执行Agent返回之后，把他给出的执行结果加入到历史执行记录里。然后把用户问题、第一个执行计划和历史执行记录一起发给Replan模型，让他给出第二个执行计划。

第一个执行计划和第二个执行计划有两点不同。

首先，原来“查询当前日期”的那一步就不用出现在第二个执行计划里面了，毕竟已经执行完了，不用再执行了。另外，“查询澳网男子冠军名字”的这一步呢，也发生了一些变化。在第一个执行计划中，它叫做“查询对应日期的澳网男子冠军名字”；在第二个执行计划中，它叫做“查询2025年的澳网男子冠军名字”。毕竟日期已经查出来了，因此可以直接把具体的年份放到执行计划里，这样执行Agent接到的任务就更加精确了。

然后进入到第二轮。在这一轮中，同样先取出最新的执行计划，发给执行Agent，让他执行其中的第一步。拿到执行结果后，再把执行结果加入到历史执行记录中。然后在Replan阶段，把用户问题、执行计划和历史执行记录发给Replan模型，拿到第三个执行计划。

在第三轮中，还是先取出执行计划，让执行Agent处理其中的第一步（当然现在也只剩一步了）。执行之后，就可以拿到一个执行结果，把执行结果加入到历史执行记录里。然后再把用户问题、执行计划和历史执行记录都发给Replan模型，让它再生成一个……哎，好像所有的任务都已经完成了，没有步骤要做了吧？

没错，在最后一轮中，Replan模型会发现所有的步骤都已经做完了，用户的问题可以回答出来了。此时Replan模型返回的就不是最新的执行计划了，而是最终的答案。

所以回头看一下，之前说“Agent的主程序请求Replan模型给出一个新的执行计划”，这个说法呢其实并不准确。更准确的说法是：Agent的主程序请求Replan模型给出一个新的执行计划或者是返回最终答案。

如果还有步骤要执行的话呢，那就给出一个新的计划；如果没有步骤要做了，用户的问题已经回答出来了，那Replan模型就返回最终答案就好了。因此Replan模型的返回呢也有两种可能性：新的执行计划或者是最终答案。

# 最后

总的来说，Agent是一种将大语言模型与工具结合起来的智能系统，使其能感知和改变外部环境。

相比只能被动生成内容的大模型，Agent通过调用文件读写、网络搜索等工具，能自主完成任务，就像一个拥有感官和四肢的机器人。

目前最主流的运行模式是ReAct，它让Agent循环执行“思考（Thought）-行动（Action）-观察（Observation）”的流程，直到得出最终答案。另一种常见模式是“规划与执行”，Agent先制定详细计划，再分步执行并根据结果动态调整。

通过精心设计的系统提示词，可以引导模型严格按照这些模式工作。开发者已经能够构建出实用的Agent，例如自动编写完整程序的代码助手，这标志着AI正从“对话工具”向能独立行动的“智能体”演进。